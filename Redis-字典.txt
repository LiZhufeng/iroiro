话不多说，一起直接看下字典的数据结构：

https://redisbook.readthedocs.io/en/latest/internal-datastruct/dict.html



一、向字典中插入键值对
1、插入过程
首先计算哈希值，算法：murmurhash

然后将哈希值 & sizemask（永远等于size - 1），计算出index
这种计算的原理是什么？与和取模有什么关系？
---> 与和取模应该是没什么关系的

最后插入键值对，如果有冲突，直接将key---value 继续插入到队列后面即可
Hset key field value 这种用的是什么数据结构？

解决冲突

二、rehash
这个和GC 的其中一种回收算法（复制算法？）有点类似
就是重新整理hash表。进行扩展或者收缩。

大概来说扩容的方式就是根据used，也就是已有的键值对数量，乘以 2^n进行扩容，最后size 更新为 大于或者等于 size*2^n 的最小2的n次幂。
先将 h[1] 进行扩容，然后将h[0]的键值对全部重新 计算hash，插入到 h[1]，最后将 h[1]和 h[0] 交换一下就可以了。

rehash的过程中如果发生了插入会怎么处理？
---> 应该是会暂停插入的

三、字典的扩展
两种情况下会进行扩展
设计也是 考虑到空间利用性
1、当负载因子（used / size）超过 1.0 并且没有进行 BGSave和BGREWRITEAOF 操作的时候

2、有进行 BGSave和BGREWRITEAOF 操作并且负载因子大于5.0的时候

四、渐进式哈希：rehash
一句话概述，就是扩展的过程不是一步到位的，而是慢慢地将h[0] 当中的每一个数据移动到 h[1]，在这个中间的过程中允许对redis数据进行查询、删除、更新等操作。
毕竟如果数据达到百万级别，一次哈希的过程往往需要很长时间。总不可能在扩展的时候什么都不让人做吧？
